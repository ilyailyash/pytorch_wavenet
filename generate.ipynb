{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named queue",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-93f1a5d5c5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mqueue\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mFILE_PATTERN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'p([0-9]+)_([0-9]+)\\.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named queue"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.nn import init\n",
    "import math\n",
    "from ops import mu_law_encode, one_hot, time_to_batch, batch_to_time, mu_law_decode\n",
    "from model import WaveNetModel\n",
    "from audio_reader import AudioReader\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "import time\n",
    "import queue as Queue\n",
    "import json\n",
    "FILE_PATTERN = r'p([0-9]+)_([0-9]+)\\.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./wavenet_params.json', 'r') as config_file:\n",
    "    wavenet_params = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = WaveNetModel(\n",
    "                 wavenet_params[\"batch_size\"],\n",
    "                 wavenet_params[\"dilations\"],\n",
    "                 wavenet_params[\"filter_width\"],\n",
    "                 wavenet_params[\"residual_channels\"],\n",
    "                 wavenet_params[\"dilation_channels\"],\n",
    "                 wavenet_params[\"skip_channels\"],\n",
    "                 quantization_channels = wavenet_params[\"quantization_channels\"],\n",
    "                 use_biases = wavenet_params[\"use_biases\"],\n",
    "                 scalar_input = wavenet_params[\"scalar_input\"],\n",
    "                 use_cuda = wavenet_params[\"use_cuda\"],\n",
    "                 initial_filter_width = wavenet_params[\"initial_filter_width\"],\n",
    "                 global_condition_channels=None,\n",
    "                 global_condition_cardinality=None)\n",
    "if model.use_cuda:\n",
    "    model = model.cuda()\n",
    "model.load_state_dict(torch.load('/home/administrator/workspace/true_model/logdir/epoch300-loss=1.773_model.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   231\n",
      "0.12192130088806152\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tried to construct a tensor from a float sequence, but found an item of type numpy.int64 at index (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1f1a3edc2f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mapmlitude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba_incremental\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapmlitude\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba_incremental\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapmlitude\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tried to construct a tensor from a float sequence, but found an item of type numpy.int64 at index (0)"
     ]
    }
   ],
   "source": [
    "num_iters = 10000\n",
    "waveform = [model.quantization_channels / 2] * (model.receptive_field - 1)\n",
    "waveform.append(np.random.randint(model.quantization_channels))\n",
    "for i, x in enumerate(waveform):\n",
    "    if model.use_cuda:    \n",
    "        loss = model.predict_proba_incremental(autograd.Variable(torch.FloatTensor([x])).cuda())\n",
    "    else:\n",
    "        loss = model.predict_proba_incremental(autograd.Variable(torch.FloatTensor([x])))   \n",
    "start_time = time.time()\n",
    "waveform = [waveform[-1]]\n",
    "for it in range(num_iters):\n",
    "    model.zero_grad()\n",
    "    apmlitude = waveform[-1]\n",
    "    if model.use_cuda:    \n",
    "        loss = model.predict_proba_incremental(autograd.Variable(torch.FloatTensor([apmlitude.astype(float)])).cuda())\n",
    "    else:\n",
    "        loss = model.predict_proba_incremental(autograd.Variable(torch.FloatTensor([apmlitude.astype(float)])))\n",
    "    if model.use_cuda:  \n",
    "        index = np.random.choice(np.arange(model.quantization_channels),p=loss.cpu().data.numpy())\n",
    "    else:\n",
    "        index = np.random.choice(np.arange(model.quantization_channels),p=loss.data.numpy())\n",
    "    #_, index = torch.max(loss,1)\n",
    "    #index = index.cpu().data.numpy()[0]\n",
    "    if it % 100 == 0:\n",
    "        print (it,' ',index)\n",
    "        print (time.time() - start_time)\n",
    "    waveform.append(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   68\n",
      "590.9403784275055\n",
      "100   5\n",
      "595.8926148414612\n",
      "200   23\n",
      "600.1210551261902\n",
      "300   48\n",
      "604.8428466320038\n",
      "400   92\n",
      "608.4205298423767\n",
      "500   50\n",
      "613.4706163406372\n",
      "600   153\n",
      "618.3117105960846\n",
      "700   126\n",
      "621.7160153388977\n",
      "800   195\n",
      "625.2276086807251\n",
      "900   28\n",
      "630.2861328125\n",
      "1000   185\n",
      "633.8129954338074\n",
      "1100   227\n",
      "639.0368657112122\n",
      "1200   79\n",
      "642.9706246852875\n",
      "1300   67\n",
      "647.7975232601166\n",
      "1400   65\n",
      "651.53937458992\n",
      "1500   62\n",
      "655.1185615062714\n",
      "1600   75\n",
      "660.8131058216095\n",
      "1700   62\n",
      "665.7906303405762\n",
      "1800   218\n",
      "671.3805019855499\n",
      "1900   64\n",
      "675.4747653007507\n",
      "2000   25\n",
      "679.3875186443329\n",
      "2100   183\n",
      "684.8002252578735\n",
      "2200   46\n",
      "688.5876297950745\n",
      "2300   175\n",
      "692.4144303798676\n",
      "2400   88\n",
      "697.6148805618286\n",
      "2500   37\n",
      "701.5752880573273\n",
      "2600   4\n",
      "705.3892149925232\n",
      "2700   224\n",
      "711.5889971256256\n",
      "2800   73\n",
      "716.7163963317871\n",
      "2900   68\n",
      "723.4136481285095\n",
      "3000   12\n",
      "727.636075258255\n",
      "3100   45\n",
      "732.4722464084625\n",
      "3200   164\n",
      "738.8399014472961\n",
      "3300   56\n",
      "743.4542207717896\n",
      "3400   53\n",
      "748.7725694179535\n",
      "3500   228\n",
      "754.9056000709534\n",
      "3600   101\n",
      "759.6496863365173\n",
      "3700   83\n",
      "765.7321245670319\n",
      "3800   233\n",
      "769.8164298534393\n",
      "3900   31\n",
      "774.9575099945068\n",
      "4000   69\n",
      "781.4219226837158\n",
      "4100   179\n",
      "785.5799477100372\n",
      "4200   27\n",
      "789.5614311695099\n",
      "4300   33\n",
      "795.8246960639954\n",
      "4400   70\n",
      "800.0505933761597\n",
      "4500   51\n",
      "805.8301980495453\n",
      "4600   78\n",
      "809.8459548950195\n",
      "4700   67\n",
      "813.9118161201477\n",
      "4800   48\n",
      "819.5441491603851\n",
      "4900   127\n",
      "823.7838821411133\n",
      "5000   150\n",
      "827.815464258194\n",
      "5100   24\n",
      "833.3318276405334\n",
      "5200   61\n",
      "837.4597799777985\n",
      "5300   25\n",
      "843.2059392929077\n",
      "5400   163\n",
      "847.3056423664093\n",
      "5500   221\n",
      "851.3139753341675\n",
      "5600   187\n",
      "856.8191106319427\n",
      "5700   43\n",
      "860.779280424118\n",
      "5800   44\n",
      "864.779354095459\n",
      "5900   229\n",
      "870.2358374595642\n",
      "6000   226\n",
      "874.108583688736\n",
      "6100   194\n",
      "879.7717835903168\n",
      "6200   212\n",
      "885.0802721977234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7ce4aa0e54ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mapmlitude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba_incremental\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapmlitude\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba_incremental\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapmlitude\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/administrator/workspace/true_model/model.py\u001b[0m in \u001b[0;36mpredict_proba_incremental\u001b[1;34m(self, waveform, global_condition)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;31m#gc_embedding = self._embed_gc(global_condition)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mraw_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/administrator/workspace/true_model/model.py\u001b[0m in \u001b[0;36m_create_generator\u001b[1;34m(self, input_batch, global_condition_batch)\u001b[0m\n\u001b[0;32m    286\u001b[0m             output, current_layer = self._generator_dilation_layer(\n\u001b[0;32m    287\u001b[0m                 \u001b[0mcurrent_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m                 global_condition_batch)\n\u001b[0m\u001b[0;32m    289\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/administrator/workspace/true_model/model.py\u001b[0m in \u001b[0;36m_generator_dilation_layer\u001b[1;34m(self, input_batch, state_batch, layer_index, dilation, global_condition_batch)\u001b[0m\n\u001b[0;32m    233\u001b[0m             input_batch, state_batch, weights_filter)\n\u001b[0;32m    234\u001b[0m         output_gate = self._generator_conv(\n\u001b[1;32m--> 235\u001b[1;33m             input_batch, state_batch, weights_gate)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mglobal_condition_batch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/administrator/workspace/true_model/model.py\u001b[0m in \u001b[0;36m_generator_conv\u001b[1;34m(self, input_batch, state_batch, weights)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;31m# TODO generalize to filter_width > 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mpast_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mcurr_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/administrator/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(self, dim1, dim2)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mTranspose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "waveform = [waveform[-1]]\n",
    "for it in range(num_iters):\n",
    "    model.zero_grad()\n",
    "    apmlitude = waveform[-1]\n",
    "    if model.use_cuda:    \n",
    "        loss = model.predict_proba_incremental(autograd.Variable(torch.FloatTensor([apmlitude.astype(float)])).cuda())\n",
    "    else:\n",
    "        loss = model.predict_proba_incremental(autograd.Variable(torch.FloatTensor([apmlitude.astype(float)])))\n",
    "    if model.use_cuda:  \n",
    "        index = np.random.choice(np.arange(model.quantization_channels),p=loss.cpu().data.numpy())\n",
    "    else:\n",
    "        index = np.random.choice(np.arange(model.quantization_channels),p=loss.data.numpy())\n",
    "    #_, index = torch.max(loss,1)\n",
    "    #index = index.cpu().data.numpy()[0]\n",
    "    if it % 100 == 0:\n",
    "        print (it,' ',index)\n",
    "        print (time.time() - start_time)\n",
    "    waveform.append(index.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_save = autograd.Variable(torch.FloatTensor(waveform))\n",
    "to_save = mu_law_decode(to_save,256)\n",
    "librosa.output.write_wav('new_gen.wav', to_save.data.numpy(), 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apmlitude.astype(float).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
